{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thresh2binarygrid(img, gridsize=(10,10), percentage=0.20):\n",
    "    \"\"\" Takes a thresholded image (i.e. from a cv2.inRange operation), divides\n",
    "    the image into a grid of gridsize; if a gridblock has percentage white pixels,\n",
    "    the gridblock will be \"turned on\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img: np.array, shape (image pixel height, image pixel width)\n",
    "        values should be between 0 - 255.\n",
    "\n",
    "    gridsize: tuple, default (10, 10)\n",
    "\n",
    "    percentage: float, between 0 - 1\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    grid: binary grid of size gridsize\n",
    "    \"\"\"\n",
    "    gridrows, gridcols = gridsize\n",
    "    m, n = img.shape\n",
    "    \n",
    "    # initialize binary grid\n",
    "    grid = np.zeros(gridsize)\n",
    "    \n",
    "    # define the size of each grid block\n",
    "    block_size = (m/gridrows, n/gridcols)\n",
    "\n",
    "    for i in range(gridrows):\n",
    "        for j in range(gridcols):\n",
    "            block = img[int(block_size[0]*i):int(block_size[0]*(i+1)), int(block_size[1]*j):int(block_size[1]*(j+1))]\n",
    "\n",
    "            # if percentage of the block was white (inRange)\n",
    "            threshold = block_size[0] * block_size[1] * 255 * percentage\n",
    "            if block.sum() >= threshold:\n",
    "                # turn the gridblock on\n",
    "                grid[i,j] = 1\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def get_bbox_from_grid(img, grid):\n",
    "    \"\"\" Gets a bounding box in the form of (pt1, pt2), pairs of (x,y)\n",
    "    coordinates the define the lefttop and rightbottom of the bounding rectangle \"\"\"\n",
    "\n",
    "    # get top\n",
    "    for i in range(grid.shape[0]):\n",
    "        if grid[i].sum() > 0:\n",
    "            top = i - 1\n",
    "            break\n",
    "    \n",
    "    # get left\n",
    "    for j in range(grid.shape[1]):\n",
    "        if grid[:, j].sum() > 0:\n",
    "            left = j - 1\n",
    "            break\n",
    "        \n",
    "    # get bottom\n",
    "    for i in range(grid.shape[0] - 1, -1, -1):\n",
    "        if grid[i].sum() > 0:\n",
    "            bottom = i + 1\n",
    "            break\n",
    "            \n",
    "    # get right\n",
    "    for j in range(grid.shape[1] - 1, -1, -1):\n",
    "        if grid[:, j].sum() > 0:\n",
    "            right = j + 1\n",
    "            break\n",
    "    \n",
    "    # (x, y)\n",
    "    pt1 = (img.shape[1]/grid.shape[1]*left, img.shape[0]/grid.shape[0]*top)\n",
    "    \n",
    "    # (right+1) and (bottom+1) cuz grid only represents the left hand corner of a block\n",
    "    pt2 = (img.shape[1]/grid.shape[1]*(right+1), img.shape[0]/grid.shape[0]*(bottom+1))\n",
    "    \n",
    "    return pt1, pt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MIN_MATCH_COUNT = 10\n",
    "minyellow = np.array([23,175,130]) \n",
    "maxyellow = np.array([32,255,255])  \n",
    "\n",
    "img2 = cv2.imread('images/leftturn_box_small.png',0) # #templateImage\n",
    "\n",
    "img1_3channel = cv2.imread('images/uturn_box.png')\n",
    "img1 = cv2.imread('images/leftturn_scene.jpg') # sceneImage\n",
    "\n",
    "hsv_image = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)\n",
    "binarized_image = cv2.inRange(hsv_image, minyellow, maxyellow)\n",
    "binaryGrid = thresh2binarygrid(binarized_image, gridsize=(15, 15), percentage=0.2)\n",
    "pt1, pt2 = get_bbox_from_grid(binarized_image, binaryGrid)\n",
    "cropped_sign = img1[pt1[1]:pt2[1], pt1[0]:pt2[0]]\n",
    "img1 = cv2.cvtColor(cropped_sign, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiate SIFT detector\n",
    "sift = cv2.SIFT()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1,des2,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bf = cv2.BFMatcher()\n",
    "# # matches = bf.knnMatch(des1, des2, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store all the good matches as per Lowe's ratio test.\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(good)\n",
    "for match in sorted(good, key=lambda val: val.distance):\n",
    "    print match.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawMatches(img1, kp1, img2, kp2, matches, masks):\n",
    "    \"\"\"\n",
    "    My own implementation of cv2.drawMatches as OpenCV 2.4.9\n",
    "    does not have this function available but it's supported in\n",
    "    OpenCV 3.0.0\n",
    "\n",
    "    This function takes in two images with their associated \n",
    "    keypoints, as well as a list of DMatch data structure (matches) \n",
    "    that contains which keypoints matched in which images.\n",
    "\n",
    "    An image will be produced where a montage is shown with\n",
    "    the first image followed by the second image beside it.\n",
    "\n",
    "    Keypoints are delineated with circles, while lines are connected\n",
    "    between matching keypoints.\n",
    "\n",
    "    img1,img2 - Grayscale images\n",
    "    kp1,kp2 - Detected list of keypoints through any of the OpenCV keypoint \n",
    "              detection algorithms\n",
    "    matches - A list of matches of corresponding keypoints through any\n",
    "              OpenCV keypoint matching algorithm\n",
    "    masks - a list of which matches are inliers (1?) or outliers (0?)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a new output image that concatenates the two images together\n",
    "    # (a.k.a) a montage\n",
    "    rows1 = img1.shape[0]\n",
    "    cols1 = img1.shape[1]\n",
    "    rows2 = img2.shape[0]\n",
    "    cols2 = img2.shape[1]\n",
    "\n",
    "    out = np.zeros((max([rows1,rows2]),cols1+cols2,3), dtype='uint8')\n",
    "\n",
    "    # Place the first image to the left\n",
    "    out[:rows1,:cols1] = np.dstack([img1, img1, img1])\n",
    "\n",
    "    # Place the next image to the right of it\n",
    "    out[:rows2,cols1:] = np.dstack([img2, img2, img2])\n",
    "\n",
    "    # For each pair of points we have between both images\n",
    "    # draw circles, then connect a line between them\n",
    "    for mask, mat in zip(masks,matches):\n",
    "\n",
    "        # Get the matching keypoints for each of the images\n",
    "        img1_idx = mat.queryIdx\n",
    "        img2_idx = mat.trainIdx\n",
    "\n",
    "        # x - columns\n",
    "        # y - rows\n",
    "        (x1,y1) = kp1[img1_idx].pt\n",
    "        (x2,y2) = kp2[img2_idx].pt\n",
    "\n",
    "        # Draw a small circle at both co-ordinates\n",
    "        # radius 4\n",
    "        # colour blue\n",
    "        # thickness = 1\n",
    "        \n",
    "        cv2.circle(out, (int(x1),int(y1)), 4, (255*mask, 0, 255*(1-mask)), 1)   \n",
    "        cv2.circle(out, (int(x2)+cols1,int(y2)), 4, (255*mask, 0, 255*(1-mask)), 1)\n",
    "\n",
    "        # Draw a line in between the two points\n",
    "        # thickness = 1\n",
    "        # colour blue\n",
    "        cv2.line(out, (int(x1),int(y1)), (int(x2)+cols1,int(y2)), (255, 0, 0), 1)\n",
    "\n",
    "\n",
    "    # Show the image\n",
    "    cv2.imshow('Matched Features', out)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyWindow('Matched Features')\n",
    "\n",
    "    # Also return the image if you'd like a copy\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show only the top 10 matches - also save a copy for use later\n",
    "# out = drawMatches(img1, kp1, img2, kp2, good[:15], mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_pts = np.float32([kp1[match.queryIdx].pt for match in good]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([kp2[match.trainIdx].pt for match in good]).reshape(-1,1,2)\n",
    "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "matchesMask = mask.ravel().tolist()\n",
    "\n",
    "print M\n",
    "\n",
    "print mask\n",
    "\n",
    "h,w = img1.shape\n",
    "pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "dst = cv2.perspectiveTransform(pts, M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kai = np.asarray(img1_3channel, dtype='float32')\n",
    "print kai.shape\n",
    "print M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_T = cv2.warpPerspective(img1, M, img2.shape[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import norm\n",
    "from scipy import sum, average\n",
    "\n",
    "def compare_images(img1, img2):\n",
    "    # normalize to compensate for exposure difference, this may be unnecessary\n",
    "    # consider disabling it\n",
    "    img1 = normalize(img1)\n",
    "    img2 = normalize(img2)\n",
    "    # calculate the difference and its norms\n",
    "    diff = img1 - img2  # elementwise for scipy arrays\n",
    "    m_norm = sum(abs(diff))  # Manhattan norm\n",
    "    z_norm = norm(diff.ravel(), 0)  # Zero norm\n",
    "    return (m_norm, z_norm)\n",
    "\n",
    "def to_grayscale(arr):\n",
    "    \"If arr is a color image (3D array), convert it to grayscale (2D array).\"\n",
    "    if len(arr.shape) == 3:\n",
    "        return average(arr, -1)  # average over the last axis (color channels)\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "def normalize(arr):\n",
    "    rng = arr.max()-arr.min()\n",
    "    amin = arr.min()\n",
    "    return (arr-amin)*255/rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare_images(img_T, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_images(img_T, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.sum(img_T - img2)\n",
    "print sum(sum(img_T - img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.sum(img_T - img2)\n",
    "print sum(sum(img_T - img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = drawMatches(img1, kp1, img2, kp2, good, matchesMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [4, 5], [7, 8]], dtype='float32')\n",
    "h = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "pointsOut = cv2.perspectiveTransform(kai[:,:,:2], M)\n",
    "print a\n",
    "# print h\n",
    "print pointsOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(pointsOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
